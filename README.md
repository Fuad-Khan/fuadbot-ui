
# ğŸ¤– FuadBot â€” AI Chatbot Powered by LLaMA 3 (Groq)

[ğŸš€ Live Demo](https://fuadbot-ui.vercel.app/)

FuadBot is a Gen-Z-style AI chatbot built by **Fuad Khan**, a Software Engineering student at Daffodil International University. It runs on **LLaMA 3 (Groq)** and is designed to answer short, focused, and fast â€” like a true digital twin ğŸ”¥

---

## ğŸ–¼ï¸ Screenshot

![FuadBot Screenshot](images/Screenshot.png)

---

## ğŸ§  Features

- âš¡ Powered by **LLaMA 3** via **Groq API**
- âœ¨ Speaks like a chill Gen-Z dev
- ğŸ“© Replies are short, focused, and friendly
- ğŸ§¼ Chat reset support
- ğŸ’¬ Markdown-style formatting support (bold, italic, lists, line breaks)
- â˜ï¸ Frontend on **Vercel**, backend on **Render** (FastAPI)

---

## ğŸ› ï¸ Tech Stack

### Frontend
- HTML, CSS, JavaScript
- Simple fetch-based API calls
- Hosted on [Vercel](https://vercel.com)

### Backend
- **Python 3 + FastAPI + Uvicorn**
- Groq API (LLaMA 3 `llama3-8b-8192`)
- Hosted on [Render](https://render.com)
- `/chat` endpoint that accepts `{ "message": "..." }` and returns `{ "reply": "..." }`

---

## ğŸŒ Live Links

| Part           | URL |
|----------------|-----|
| ğŸ§© Frontend    | https://fuadbot-ui.vercel.app |
| ğŸ”§ Backend API | https://fuadbot-api.onrender.com/chat |

---

## ğŸ“ Repositories

| Name              | Link |
|-------------------|------|
| ğŸ–¼ï¸ Frontend Repo  | https://github.com/Fuad-Khan/fuadbot-ui |
| âš™ï¸ Backend Repo   | https://github.com/Fuad-Khan/fuadbot-api |

---

## ğŸš€ Local Setup (Frontend Only)

You can run the frontend locally as a static site and still call the deployed backend.

```bash
git clone https://github.com/Fuad-Khan/fuadbot-ui.git
cd fuadbot-ui
````

Then either:

* Open `frontend/index.html` directly in your browser, **or**
* Use a simple static server (recommended):

### Using Python (3.x)

```bash
cd frontend
python -m http.server 5500
```

Now open:

```text
http://localhost:5500/index.html
```

---

## ğŸ”— Configuring the API Endpoint

In `frontend/chatbot.js`, make sure the API URL points to your backend:

```js
const API_URL = "https://fuadbot-api.onrender.com/chat";
```

If you run a backend locally (FastAPI), you can temporarily change it to:

```js
const API_URL = "http://localhost:5000/chat";
```

---

## ğŸ’¡ How It Works (High Level)

1. User types a message in the chat box.
2. Frontend sends a `POST` request to the backend `/chat` endpoint:

   ```json
   {
     "message": "Your message here"
   }
   ```
3. Backend (FastAPI + Groq) sends the prompt + system instructions to LLaMA 3.
4. Backend returns:

   ```json
   {
     "reply": "AI response here"
   }
   ```
5. Frontend renders the response in the chat UI.


